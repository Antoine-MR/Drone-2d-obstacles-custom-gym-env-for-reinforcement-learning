# Eureka + Drone 2D Integration Guide

## Objective
Integrate custom 2D drone environment with Eureka for automatic reward function optimization via LLM.

## Architecture

### 1. Eureka Environment Configuration
- **`eureka/cfg/env/drone_2d.yaml`** : Drone environment configuration for Eureka
- **`eureka/envs/drone_2d/`** : Drone environment package adapted for Eureka
  - `drone_2d_env.py` : Main wrapper and reward functions
  - `drone_2d_temp.py` : Reward function template for optimization
  - `drone_2d_obs.py` : Environment definition and observations

### 2. RL-Baselines3-Zoo Integration
- **`rl-baselines3-zoo/rl_zoo3/drone_2d_custom.py`** : Custom drone environment
- **`rl-baselines3-zoo/hyperparams/ppo.yml`** : Hyperparameters for Drone2D-v0
- **`rl-baselines3-zoo/rl_zoo3/import_envs.py`** : Environment registration

### 3. Eureka Configuration
- **`eureka/cfg/config.yaml`** : Modified to use drone_2d by default
- **`eureka/eureka.py`** : Adaptations to support different environments

## State and Action Spaces

### Observations (8D)
```
obs[0]: velocity_x     (normalized X velocity, -1 to 1)
obs[1]: velocity_y     (normalized Y velocity, -1 to 1)  
obs[2]: angular_vel    (normalized angular velocity, -1 to 1)
obs[3]: angle          (angle du drone normalis√©, -1 √† 1)
obs[4]: distance_x     (distance X √† la cible normalis√©e, -1 √† 1)
obs[5]: distance_y     (distance Y √† la cible normalis√©e, -1 √† 1)
obs[6]: pos_x          (position X absolue normalis√©e, -1 √† 1)
obs[7]: pos_y          (position Y absolue normalis√©e, -1 √† 1)
```

### Actions (2D)
```
action[0]: left_motor  (force moteur gauche, -1 √† 1)  
action[1]: right_motor (force moteur droite, -1 √† 1)
```

## üéØ Fonction de Reward de Base
La fonction initiale optimise :
- **Distance √† la cible** : R√©compense inversement proportionnelle √† la distance
- **Stabilit√©** : P√©nalise les vitesses angulaires et angles √©lev√©s  
- **Contr√¥le fluide** : P√©nalise les actions brusques
- **P√©nalit√© terminale** : Malus important si le drone sort des limites

## üöÄ Comment utiliser

### 1. Pr√©-requis
```bash
# Installer Ollama et llama3.1
ollama pull llama3.1

# Installer les d√©pendances
pip install --user ollama hydra-core omegaconf
```

### 2. Lancement simple
```bash
cd Eureka_for_carracing-master/Eureka_for_carracing-master
python launch_drone_eureka.py
```

### 3. Lancement avanc√©
```bash
python eureka/eureka.py \
  env=drone_2d \
  iteration=10 \
  sample=3 \
  max_iterations=3000 \
  model=llama3.1 \
  suffix=drone_test
```

### 4. Test de l'environnement
```bash
python test_drone_env.py
```

## üìä Hyperparam√®tres PPO pour Drone2D
```yaml
Drone2D-v0:
  n_envs: 4
  n_timesteps: 3000
  policy: 'MlpPolicy'
  n_steps: 256
  batch_size: 64
  learning_rate: 3e-4
  # ... voir ppo.yml pour la configuration compl√®te
```

## üîÑ Processus Eureka
1. **G√©n√©ration** : Le LLM g√©n√®re des nouvelles fonctions de reward
2. **Entra√Ænement** : PPO entra√Æne un agent avec chaque fonction
3. **√âvaluation** : Test de performance de chaque agent
4. **S√©lection** : Garde les meilleures fonctions pour la prochaine it√©ration
5. **It√©ration** : R√©p√®te le processus pour am√©liorer progressivement

## üìà Fichiers de sortie
- **`rl_zoo3/drone_2d_custom.py`** : Fonction de reward optimale finale
- **`outputs/`** : Logs et r√©sultats d'entra√Ænement par it√©ration
- **R√©pertoires temporaires** : Agents et codes g√©n√©r√©s par it√©ration

## üéõÔ∏è Param√®tres d'optimisation
- `iteration` : Nombre d'it√©rations Eureka (d√©faut: 10)
- `sample` : Nombre d'√©chantillons de reward par it√©ration (d√©faut: 3) 
- `max_iterations` : Nombre d'√©tapes d'entra√Ænement RL (d√©faut: 3000)
- `temperature` : Cr√©ativit√© du LLM (d√©faut: 1.0)

## üêõ Troubleshooting

### Erreur d'import du drone
```bash
pip install --user -e /path/to/drone_2d_custom_gym_env_package
```

### Ollama non disponible
```bash
ollama serve  # Dans un terminal s√©par√©
ollama pull llama3.1
```

### Probl√®me de chemins
V√©rifiez que tous les `sys.path.insert()` pointent vers le bon r√©pertoire du package drone.

## ‚úÖ Status
- ‚úÖ Environnement drone int√©gr√©
- ‚úÖ Configuration Eureka adapt√©e  
- ‚úÖ Hyperparam√®tres PPO configur√©s
- ‚úÖ Tests fonctionnels pass√©s
- ‚úÖ Fichiers CarRacing pr√©serv√©s
- üîÑ Pr√™t pour l'optimisation Eureka !

---

Le syst√®me est maintenant configur√© pour optimiser automatiquement la fonction de reward du drone via Eureka tout en pr√©servant l'environnement CarRacing existant.