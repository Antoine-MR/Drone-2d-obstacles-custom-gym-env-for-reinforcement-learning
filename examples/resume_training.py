from stable_baselines3 import PPO
from stable_baselines3.common.callbacks import BaseCallback
import gymnasium as gym
import sys
import os
import signal
import time

# Ajouter le chemin vers le package local
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'drone_2d_custom_gym_env_package'))

import drone_2d_custom_gym_env

class KeyboardInterruptCallback(BaseCallback):
    """Callback pour gÃ©rer l'arrÃªt manuel avec Ctrl+C"""
    
    def __init__(self, save_path="checkpoint_agent", verbose=0):
        super(KeyboardInterruptCallback, self).__init__(verbose)
        self.save_path = save_path
        self.interrupted = False
        
    def _on_step(self) -> bool:
        # Sauvegarder pÃ©riodiquement (toutes les 50000 Ã©tapes)
        if self.n_calls % 50000 == 0:
            checkpoint_path = f"{self.save_path}_step_{self.n_calls}"
            self.model.save(checkpoint_path)
            print(f"ğŸ”„ Checkpoint sauvegardÃ©: {checkpoint_path}")
        
        return not self.interrupted
    
    def on_keyboard_interrupt(self):
        """MÃ©thode appelÃ©e lors d'un Ctrl+C"""
        self.interrupted = True
        final_path = f"{self.save_path}_interrupted_{int(time.time())}"
        self.model.save(final_path)
        print(f"\nâš ï¸  EntraÃ®nement interrompu! ModÃ¨le sauvegardÃ©: {final_path}")

# Variable globale pour le callback
interrupt_callback = None

def signal_handler(sig, frame):
    """Gestionnaire de signal pour Ctrl+C"""
    if interrupt_callback:
        interrupt_callback.on_keyboard_interrupt()
    print("\nâš ï¸  ArrÃªt en cours... Veuillez patienter pour la sauvegarde.")

# Configuration du gestionnaire de signal
signal.signal(signal.SIGINT, signal_handler)

# CrÃ©er l'environnement
env = gym.make('drone-2d-custom-v0', render_sim=False, render_path=False, render_shade=False,
            shade_distance=70, n_steps=500, n_fall_steps=10, change_target=True, initial_throw=True)

# CrÃ©er le callback d'interruption
interrupt_callback = KeyboardInterruptCallback(save_path="checkpoint_agent", verbose=1)

# REPRENDRE DEPUIS LE CHECKPOINT D'INTERRUPTION
checkpoint_path = "../checkpoint_agent_interrupted_1759758715"
print(f"ğŸ”„ Chargement du checkpoint: {checkpoint_path}")

try:
    model = PPO.load(checkpoint_path, env=env)
    print("âœ… Checkpoint chargÃ© avec succÃ¨s!")
except Exception as e:
    print(f"âŒ Erreur lors du chargement du checkpoint: {e}")
    print("ğŸ†• CrÃ©ation d'un nouveau modÃ¨le...")
    model = PPO("MlpPolicy", env, verbose=1, tensorboard_log="../tensorboard_logs/")

# Calculer les Ã©tapes restantes
total_timesteps = 1800000
steps_completed = 456705  # Ã‰tapes dÃ©jÃ  complÃ©tÃ©es selon votre log
remaining_steps = total_timesteps - steps_completed

print("ğŸ“Š Informations de reprise:")
print(f"   â€¢ Ã‰tapes complÃ©tÃ©es: {steps_completed:,}")
print(f"   â€¢ Ã‰tapes restantes: {remaining_steps:,}")
print(f"   â€¢ Progression: {(steps_completed/total_timesteps)*100:.1f}%")
print()
print("ğŸš€ Reprise de l'entraÃ®nement...")
print("   â€¢ Appuyez sur Ctrl+C pour arrÃªter et sauvegarder")
print("   â€¢ Checkpoints automatiques toutes les 50000 Ã©tapes")
print("   â€¢ TensorBoard logs dans ../tensorboard_logs/")
print()

try:
    model.learn(total_timesteps=remaining_steps, callback=interrupt_callback, progress_bar=True, reset_num_timesteps=False)
    # Si l'entraÃ®nement se termine normalement
    model.save('../final_agent_complete')
    print("âœ… EntraÃ®nement terminÃ©! ModÃ¨le final sauvegardÃ©: ../final_agent_complete")
    
except KeyboardInterrupt:
    print("âš ï¸  Interruption dÃ©tectÃ©e par KeyboardInterrupt")
    pass

print("ğŸ Programme terminÃ©.")
print("ğŸ“Š Pour visualiser les mÃ©triques, lancez: tensorboard --logdir=../tensorboard_logs/")
print("ğŸŒ Puis ouvrez: http://localhost:6006")