from stable_baselines3 import PPO
import gymnasium as gym
import time
import sys
import os

sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'drone_2d_custom_gym_env_package'))

import drone_2d_custom_gym_env

continuous_mode = True #if True, after completing one episode the next one will start automatically
random_action = False #if True, the agent will take actions randomly

render_sim = True #if True, a graphic is generated

env = gym.make('drone-2d-custom-v0', render_sim=render_sim, render_path=True, render_shade=True,
            shade_distance=70, n_steps=500, n_fall_steps=10, change_target=True, initial_throw=True)

"""
Chargement du modÃ¨le entraÃ®nÃ©
Essaie plusieurs modÃ¨les dans l'ordre de prÃ©fÃ©rence
"""
# Liste des modÃ¨les Ã  essayer dans l'ordre de prÃ©fÃ©rence
model_paths = [
    "../../final_agent.zip",                              # ModÃ¨le final (s'il existe)
    "../../checkpoint_agent_interrupted_1759758715.zip",  # Checkpoint d'interruption
    "../../checkpoint_agent_step_450000.zip",             # Dernier checkpoint automatique
    "../../checkpoint_agent_step_400000.zip",             # Checkpoint prÃ©cÃ©dent
    "ppo_agents/ppo_agent.zip"                            # Agent d'exemple original
]

model = None
for model_path in model_paths:
    try:
        model = PPO.load(model_path)
        print(f"âœ… ModÃ¨le chargÃ©: {model_path}")
        break
    except FileNotFoundError:
        print(f"âš ï¸  ModÃ¨le non trouvÃ©: {model_path}")
        continue
    except Exception as e:
        print(f"âŒ Erreur lors du chargement de {model_path}: {e}")
        continue

if model is None:
    print("âŒ Aucun modÃ¨le trouvÃ©! Veuillez d'abord entraÃ®ner un modÃ¨le.")
    exit(1)

model.set_env(env)

random_seed = int(time.time())
model.set_random_seed(random_seed)

# Nouvelle API Gymnasium : env.reset() retourne (obs, info)
obs, info = env.reset()

# Variables pour les statistiques
episode_count = 0
total_reward = 0
step_count = 0

print(f"ðŸš€ DÃ©marrage de l'Ã©valuation")
print(f"   â€¢ Mode continu: {continuous_mode}")
print(f"   â€¢ Actions alÃ©atoires: {random_action}")
print(f"   â€¢ Rendu graphique: {render_sim}")
print("   â€¢ Appuyez sur Ctrl+C pour arrÃªter")

try:
    while True:
        if render_sim:
            env.render()

        if random_action:
            action = env.action_space.sample()
        else:
            action, _states = model.predict(obs, deterministic=True)

        # Nouvelle API Gymnasium : env.step() retourne (obs, reward, terminated, truncated, info)
        obs, reward, terminated, truncated, info = env.step(action)
        done = terminated or truncated
        
        total_reward += reward
        step_count += 1

        if done is True:
            episode_count += 1
            print(f"ðŸ“Š Ã‰pisode {episode_count} terminÃ©:")
            print(f"   â€¢ RÃ©compense totale: {total_reward:.2f}")
            print(f"   â€¢ Nombre d'Ã©tapes: {step_count}")
            
            if continuous_mode is True:
                obs, info = env.reset()
                total_reward = 0
                step_count = 0
            else:
                break

except KeyboardInterrupt:
    print(f"\nâš ï¸  Ã‰valuation interrompue par l'utilisateur")
    print(f"ðŸ“Š Statistiques finales:")
    print(f"   â€¢ Ã‰pisodes complÃ©tÃ©s: {episode_count}")
    if episode_count > 0:
        print(f"   â€¢ RÃ©compense de l'Ã©pisode en cours: {total_reward:.2f}")
        print(f"   â€¢ Ã‰tapes de l'Ã©pisode en cours: {step_count}")

finally:
    env.close()
