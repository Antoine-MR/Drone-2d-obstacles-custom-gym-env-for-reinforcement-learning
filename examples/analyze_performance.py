import gymnasium as gym
import sys
import os
import numpy as np
import matplotlib.pyplot as plt
from stable_baselines3 import PPO

# Ajouter le chemin vers le package local
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'drone_2d_custom_gym_env_package'))

import drone_2d_custom_gym_env

def compare_agents_with_obstacles(agent_with_obstacles_path, agent_without_obstacles_path, num_episodes=30):
    """
    Compare deux agents (avec et sans obstacles) test√©s dans un environnement AVEC obstacles sur la MAP FIXE
    """
    print(f"üî¨ COMPARAISON AGENTS - MAP FIXE AVEC OBSTACLE")
    print("=" * 80)
    print(f"ü§ñ Agent A: {agent_with_obstacles_path}")
    print(f"ü§ñ Agent B: {agent_without_obstacles_path}")
    print(f"üó∫Ô∏è  Map: Drone (150,400) ‚Üí Cible (650,400) avec obstacle central")
    print("=" * 80)
    
    # Environnement de test AVEC LA MAP FIXE
    env = gym.make('drone-2d-custom-v0', 
                   render_sim=False, render_path=False, render_shade=False,
                   n_steps=500, n_fall_steps=10, change_target=False, initial_throw=False,
                   use_obstacles=True, num_obstacles=3, fixed_map=True)
    
    def test_agent_performance(model_path, agent_name):
        """Teste un agent et retourne ses statistiques"""
        try:
            model = PPO.load(model_path)
            print(f"\n‚úÖ {agent_name} charg√© avec succ√®s!")
        except Exception as e:
            print(f"‚ùå Erreur chargement {agent_name}: {e}")
            return None
        
        rewards = []
        steps = []
        collision_obstacles = 0
        out_of_bounds = 0
        timeouts = 0
        distances_to_target = []
        
        print(f"üß™ Test de {agent_name} sur {num_episodes} √©pisodes...")
        
        for episode in range(num_episodes):
            obs, _ = env.reset()
            episode_reward = 0
            step_count = 0
            episode_distances = []
            
            while True:
                action, _ = model.predict(obs, deterministic=True)
                obs, reward, done, truncated, info = env.step(action)
                episode_reward += reward
                step_count += 1
                
                # Distance √† la cible
                distance_x = obs[4]
                distance_y = obs[5]
                distance_to_target = np.sqrt(distance_x**2 + distance_y**2)
                episode_distances.append(distance_to_target)
                
                if done or truncated:
                    break
            
            rewards.append(episode_reward)
            steps.append(step_count)
            distances_to_target.extend(episode_distances)
            
            # Analyser cause de fin d'√©pisode
            if step_count < 500:
                if abs(obs[6]) == 1 or abs(obs[7]) == 1:
                    out_of_bounds += 1
                    # print(f"   üö´ √âpisode {episode+1}: Sortie limites √† l'√©tape {step_count}")
                else:
                    collision_obstacles += 1
                    # print(f"   üí• √âpisode {episode+1}: Collision obstacle √† l'√©tape {step_count}")
            else:
                timeouts += 1
                # print(f"   ‚úÖ √âpisode {episode+1}: Survie compl√®te (500 √©tapes)")
        
        # Calculer statistiques
        stats = {
            'agent_name': agent_name,
            'avg_reward': np.mean(rewards),
            'avg_steps': np.mean(steps),
            'avg_distance': np.mean(distances_to_target),
            'survival_rate': (timeouts / num_episodes) * 100,
            'collision_rate': (collision_obstacles / num_episodes) * 100,
            'bounds_rate': (out_of_bounds / num_episodes) * 100,
            'collision_count': collision_obstacles,
            'survival_count': timeouts,
            'bounds_count': out_of_bounds,
            'rewards': rewards,
            'steps': steps
        }
        
        # Affichage des statistiques de base pour cet agent
        print(f"\nüìã R√âSUM√â {agent_name}:")
        print(f"   üéØ √âpisodes surv√©cus (500 √©tapes): {timeouts}/{num_episodes}")
        print(f"   üí• Collisions avec obstacles: {collision_obstacles}/{num_episodes}")
        print(f"   üö´ Sorties des limites: {out_of_bounds}/{num_episodes}")
        
        return stats
    
    # Tester les deux agents
    stats_with = test_agent_performance(agent_with_obstacles_path, "Agent AVEC obstacles")
    stats_without = test_agent_performance(agent_without_obstacles_path, "Agent SANS obstacles")
    
    if stats_with is None or stats_without is None:
        print("\n‚ùå ERREUR: Impossible de charger un ou plusieurs mod√®les")
        print("\nüìã MOD√àLES RECHERCH√âS:")
        print(f"   ‚Ä¢ {agent_with_obstacles_path}.zip")
        print(f"   ‚Ä¢ {agent_without_obstacles_path}.zip")
        print("\nüí° SOLUTIONS:")
        print("   ‚Ä¢ V√©rifiez que l'entra√Ænement est termin√©")
        print("   ‚Ä¢ V√©rifiez les noms de fichiers")
        print("   ‚Ä¢ Les mod√®les doivent √™tre dans le dossier examples/")
        env.close()
        return None, None
    
    # Affichage comparatif
    print(f"\nüìä R√âSULTATS COMPARATIFS:")
    print("=" * 80)
    print(f"{'M√©trique':<25} {'Agent AVEC':<15} {'Agent SANS':<15} {'Diff√©rence':<15}")
    print("-" * 80)
    
    metrics = [
        ('R√©compense moyenne', 'avg_reward', '.2f'),
        ('√âtapes moyennes', 'avg_steps', '.1f'),
        ('Distance cible', 'avg_distance', '.3f'),
        ('Taux survie (%)', 'survival_rate', '.1f'),
        ('Collision obstacles (%)', 'collision_rate', '.1f'),
        ('Sortie limites (%)', 'bounds_rate', '.1f')
    ]
    
    for metric_name, key, fmt in metrics:
        val_with = stats_with[key]
        val_without = stats_without[key]
        diff = val_with - val_without
        
        # Formatage corrig√© - enlever les deux points du d√©but
        format_spec = fmt[1:] if fmt.startswith(':') else fmt
        val_with_str = f"{val_with:{format_spec}}"
        val_without_str = f"{val_without:{format_spec}}"
        diff_str = f"{diff:+{format_spec}}"
        
        print(f"{metric_name:<25} {val_with_str:<15} {val_without_str:<15} {diff_str:<15}")
    
    # Section sp√©ciale pour les R√âUSSITES
    print(f"\nüéØ FOCUS: TAUX DE R√âUSSITE (Survie 500 √©tapes)")
    print("-" * 50)
    success_with = stats_with['survival_count']
    success_without = stats_without['survival_count']
    success_diff = success_with - success_without
    
    print(f"Agent final_agent:              {success_with}/{num_episodes} r√©ussites ({stats_with['survival_rate']:.1f}%)")
    print(f"Agent final_agentWithoutObstacle: {success_without}/{num_episodes} r√©ussites ({stats_without['survival_rate']:.1f}%)")
    print(f"Diff√©rence:                     {success_diff:+d} r√©ussites")
    
    if success_diff > 0:
        print(f"‚úÖ L'agent final_agent r√©ussit {success_diff} fois de plus sur la map!")
        print(f"   ‚Üí Entra√Æn√© avec obstacles = meilleure navigation")
    elif success_diff == 0:
        print(f"‚öñÔ∏è  Les deux agents ont le m√™me taux de r√©ussite")
    else:
        print(f"‚ö†Ô∏è  L'agent final_agentWithoutObstacle r√©ussit {abs(success_diff)} fois de plus")
    
    # Section collisions obstacles
    print(f"\nüí• FOCUS: COLLISIONS AVEC L'OBSTACLE")
    print("-" * 50)
    collision_with = stats_with['collision_count']
    collision_without = stats_without['collision_count']
    collision_reduction = collision_without - collision_with
    
    print(f"Agent final_agent:              {collision_with}/{num_episodes} collisions")
    print(f"Agent final_agentWithoutObstacle: {collision_without}/{num_episodes} collisions")
    
    if collision_reduction > 0:
        reduction_pct = (collision_reduction/collision_without*100) if collision_without > 0 else 0
        print(f"R√©duction:                      {collision_reduction:+d} collisions √©vit√©es (-{reduction_pct:.1f}%)")
        print(f"‚úÖ L'agent entra√Æn√© avec obstacles √©vite mieux l'obstacle!")
    elif collision_reduction == 0:
        print(f"‚öñÔ∏è  M√™me nombre de collisions")
    else:
        print(f"‚ö†Ô∏è  {abs(collision_reduction)} collisions de plus pour l'agent entra√Æn√©")
    
    # Analyse des r√©sultats
    print(f"\nüîç ANALYSE COMPARATIVE:")
    print("=" * 60)
    
    survival_improvement = stats_with['survival_rate'] - stats_without['survival_rate']
    collision_improvement = stats_without['collision_rate'] - stats_with['collision_rate']
    
    # Analyse de la survie
    print(f"üìä Taux de survie:")
    if survival_improvement > 20:
        print(f"   ÔøΩ EXCELLENT: +{survival_improvement:.1f}% de r√©ussite")
        print(f"   ‚Üí L'agent entra√Æn√© avec obstacles est BEAUCOUP plus performant!")
    elif survival_improvement > 10:
        print(f"   ‚úÖ TR√àS BIEN: +{survival_improvement:.1f}% de r√©ussite")
        print(f"   ‚Üí L'entra√Ænement avec obstacles a port√© ses fruits")
    elif survival_improvement > 0:
        print(f"   üëç BIEN: +{survival_improvement:.1f}% de r√©ussite")
        print(f"   ‚Üí L√©g√®re am√©lioration gr√¢ce √† l'entra√Ænement")
    elif survival_improvement == 0:
        print(f"   ‚öñÔ∏è  √âGAL: M√™me performance")
    else:
        print(f"   ‚ö†Ô∏è  SURPRENANT: {survival_improvement:.1f}% (agent sans obstacles meilleur)")
        print(f"   ‚Üí Possible que l'agent sans obstacles ait eu plus d'entra√Ænement")
    
    # Analyse des collisions
    print(f"\nüí• √âvitement des collisions:")
    if collision_improvement > 20:
        print(f"   üõ°Ô∏è  EXCELLENT: {collision_improvement:.1f}% moins de collisions")
        print(f"   ‚Üí L'agent a bien appris √† √©viter les obstacles!")
    elif collision_improvement > 10:
        print(f"   üëç BIEN: {collision_improvement:.1f}% moins de collisions")
        print(f"   ‚Üí Am√©lioration notable de la navigation")
    elif collision_improvement > 0:
        print(f"   ‚ÜóÔ∏è  L√âG√àRE AM√âLIORATION: {collision_improvement:.1f}% moins de collisions")
    elif collision_improvement == 0:
        print(f"   ‚öñÔ∏è  √âGAL: M√™me nombre de collisions")
    else:
        print(f"   ‚ö†Ô∏è  {abs(collision_improvement):.1f}% plus de collisions")
        print(f"   ‚Üí L'entra√Ænement n'a pas am√©lior√© l'√©vitement")
    
    # Recommandations
    print(f"\nüí° RECOMMANDATIONS:")
    if collision_improvement < 10:
        print("üîÑ L'agent avec obstacles peut encore s'am√©liorer:")
        print("   ‚Ä¢ Plus d'entra√Ænement (augmenter timesteps)")
        print("   ‚Ä¢ Penalty collision plus √©lev√©e (-15 au lieu de -10)")
        print("   ‚Ä¢ R√©compense pour √©vitement d'obstacles")
    
    if stats_with['survival_rate'] < 20:
        print("ÔøΩ Curriculum learning recommand√©:")
        print("   ‚Ä¢ Commencer avec 1 obstacle, puis 2, puis 3")
        print("   ‚Ä¢ Obstacles plus grands au d√©but")
    
    # Verdict final - QUI GAGNE?
    print(f"\nüèÜ VERDICT FINAL:")
    print("=" * 60)
    
    if success_with > success_without:
        winner = "final_agent (entra√Æn√© AVEC obstacles)"
        margin = success_with - success_without
        print(f"ü•á GAGNANT: {winner}")
        print(f"   ‚úÖ {success_with} r√©ussites VS {success_without} r√©ussites")
        print(f"   ‚Üí Marge de victoire: +{margin} r√©ussites sur {num_episodes} essais")
        print(f"   ÔøΩ L'entra√Ænement avec obstacles a √©t√© efficace!")
    elif success_without > success_with:
        winner = "final_agentWithoutObstacle (entra√Æn√© SANS obstacles)"
        margin = success_without - success_with
        print(f"ü•á GAGNANT: {winner}")
        print(f"   ‚úÖ {success_without} r√©ussites VS {success_with} r√©ussites")
        print(f"   ‚Üí Marge de victoire: +{margin} r√©ussites sur {num_episodes} essais")
        print(f"   ‚ö†Ô∏è  R√©sultat surprenant!")
    else:
        print(f"ü§ù √âGALIT√â PARFAITE")
        print(f"   ‚Üí Les deux agents ont {success_with} r√©ussites chacun")
        print(f"   ‚Üí Performance identique sur {num_episodes} essais")
    
    env.close()
    return stats_with, stats_without

def list_available_models():
    """Liste les mod√®les disponibles dans le r√©pertoire"""
    import glob
    
    print("üìÇ MOD√àLES DISPONIBLES:")
    print("-" * 40)
    
    # Chercher tous les fichiers .zip
    model_files = glob.glob("*.zip")
    checkpoint_files = glob.glob("checkpoint_*.zip")
    
    if model_files:
        for model in sorted(model_files):
            print(f"   ‚úÖ {model}")
    else:
        print("   ‚ùå Aucun mod√®le trouv√© dans le r√©pertoire courant")
        print("   üí° Assurez-vous d'√™tre dans le dossier examples/")
        print("   üí° L'entra√Ænement doit √™tre termin√© pour cr√©er les fichiers .zip")
    
    return model_files

if __name__ == "__main__":
    print("ü§ñ COMPARAISON AGENTS: AVEC vs SANS obstacles")
    print("=" * 60)
    
    # D'abord, lister les mod√®les disponibles
    available_models = list_available_models()
    
    if not available_models:
        print("\n‚ö†Ô∏è  Aucun mod√®le disponible pour l'analyse")
        print("\nüìö √âTAPES N√âCESSAIRES:")
        print("   1. Terminer l'entra√Ænement avec obstacles")
        print("   2. S'assurer d'avoir 'final_agentWithoutObstacle.zip'")
        print("   3. Relancer ce script")
        exit(1)
    
    # Chemins des mod√®les
    agent_with_obstacles = "final_agent"  # Agent entra√Æn√© avec obstacles
    agent_without_obstacles = "final_agentWithoutObstacle"  # Agent entra√Æn√© sans obstacles
    
    # 1. Comparaison quantitative sur 30 essais
    print("\nüî¨ ANALYSE COMPARATIVE - 30 ESSAIS CHACUN:")
    result = compare_agents_with_obstacles(
        agent_with_obstacles, 
        agent_without_obstacles, 
        num_episodes=30
    )
    
    if result is None:
        print("\n‚ö†Ô∏è  Analyse interrompue - mod√®les non disponibles")
        exit(1)
    
    stats_with, stats_without = result
    
    print("\n" + "=" * 70)
    print("üéâ ANALYSE TERMIN√âE!")
    print("=" * 70)
    print(f"‚úÖ 30 essais par agent sur la map fixe avec obstacle")
    print(f"üó∫Ô∏è  Configuration: Drone (150,400) ‚Üí Cible (650,400) + obstacle central")
    print("=" * 70)