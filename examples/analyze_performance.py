import gymnasium as gym
import sys
import os
import numpy as np
import matplotlib.pyplot as plt
from stable_baselines3 import PPO

# Ajouter le chemin vers le package local
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'drone_2d_custom_gym_env_package'))

import drone_2d_custom_gym_env

def compare_agents_with_obstacles(agent_with_obstacles_path, agent_without_obstacles_path, num_episodes=30):
    """
    Compare deux agents (avec et sans obstacles) testÃ©s dans un environnement AVEC obstacles sur la MAP FIXE
    """
    print(f"ğŸ”¬ COMPARAISON AGENTS - MAP FIXE AVEC OBSTACLE")
    print("=" * 80)
    print(f"ğŸ¤– Agent A: {agent_with_obstacles_path}")
    print(f"ğŸ¤– Agent B: {agent_without_obstacles_path}")
    print(f"ğŸ—ºï¸  Map: Drone (150,400) â†’ Cible (650,400) avec obstacle central")
    print("=" * 80)
    
    # Environnement de test AVEC LA MAP FIXE
    env = gym.make('drone-2d-custom-v0', 
                   render_sim=False, render_path=False, render_shade=False,
                   n_steps=500, n_fall_steps=10, change_target=False, initial_throw=False,
                   use_obstacles=True, num_obstacles=3, fixed_map=True)
    
    def test_agent_performance(model_path, agent_name):
        """Teste un agent et retourne ses statistiques"""
        try:
            model = PPO.load(model_path)
            print(f"\nâœ… {agent_name} chargÃ© avec succÃ¨s!")
        except Exception as e:
            print(f"âŒ Erreur chargement {agent_name}: {e}")
            return None
        
        rewards = []
        steps = []
        collision_obstacles = 0
        out_of_bounds = 0
        timeouts = 0
        distances_to_target = []
        
        print(f"ğŸ§ª Test de {agent_name} sur {num_episodes} Ã©pisodes...")
        
        for episode in range(num_episodes):
            obs, _ = env.reset()
            episode_reward = 0
            step_count = 0
            episode_distances = []
            
            while True:
                action, _ = model.predict(obs, deterministic=True)
                obs, reward, done, truncated, info = env.step(action)
                episode_reward += reward
                step_count += 1
                
                # Distance Ã  la cible
                distance_x = obs[4]
                distance_y = obs[5]
                distance_to_target = np.sqrt(distance_x**2 + distance_y**2)
                episode_distances.append(distance_to_target)
                
                if done or truncated:
                    break
            
            rewards.append(episode_reward)
            steps.append(step_count)
            distances_to_target.extend(episode_distances)
            
            # Analyser cause de fin d'Ã©pisode
            if step_count < 500:
                if abs(obs[6]) == 1 or abs(obs[7]) == 1:
                    out_of_bounds += 1
                    # print(f"   ğŸš« Ã‰pisode {episode+1}: Sortie limites Ã  l'Ã©tape {step_count}")
                else:
                    collision_obstacles += 1
                    # print(f"   ğŸ’¥ Ã‰pisode {episode+1}: Collision obstacle Ã  l'Ã©tape {step_count}")
            else:
                timeouts += 1
                # print(f"   âœ… Ã‰pisode {episode+1}: Survie complÃ¨te (500 Ã©tapes)")
        
        # Calculer statistiques
        stats = {
            'agent_name': agent_name,
            'avg_reward': np.mean(rewards),
            'avg_steps': np.mean(steps),
            'avg_distance': np.mean(distances_to_target),
            'survival_rate': (timeouts / num_episodes) * 100,
            'collision_rate': (collision_obstacles / num_episodes) * 100,
            'bounds_rate': (out_of_bounds / num_episodes) * 100,
            'collision_count': collision_obstacles,
            'survival_count': timeouts,
            'bounds_count': out_of_bounds,
            'rewards': rewards,
            'steps': steps
        }
        
        # Affichage des statistiques de base pour cet agent
        print(f"\nğŸ“‹ RÃ‰SUMÃ‰ {agent_name}:")
        print(f"   ğŸ¯ Ã‰pisodes survÃ©cus (500 Ã©tapes): {timeouts}/{num_episodes}")
        print(f"   ğŸ’¥ Collisions avec obstacles: {collision_obstacles}/{num_episodes}")
        print(f"   ğŸš« Sorties des limites: {out_of_bounds}/{num_episodes}")
        
        return stats
    
    # Tester les deux agents
    stats_with = test_agent_performance(agent_with_obstacles_path, "Agent AVEC obstacles")
    stats_without = test_agent_performance(agent_without_obstacles_path, "Agent SANS obstacles")
    
    if stats_with is None or stats_without is None:
        print("\nâŒ ERREUR: Impossible de charger un ou plusieurs modÃ¨les")
        print("\nğŸ“‹ MODÃˆLES RECHERCHÃ‰S:")
        print(f"   â€¢ {agent_with_obstacles_path}.zip")
        print(f"   â€¢ {agent_without_obstacles_path}.zip")
        print("\nğŸ’¡ SOLUTIONS:")
        print("   â€¢ VÃ©rifiez que l'entraÃ®nement est terminÃ©")
        print("   â€¢ VÃ©rifiez les noms de fichiers")
        print("   â€¢ Les modÃ¨les doivent Ãªtre dans le dossier examples/")
        env.close()
        return None, None
    
    # Affichage comparatif
    print(f"\nğŸ“Š RÃ‰SULTATS COMPARATIFS:")
    print("=" * 80)
    print(f"{'MÃ©trique':<25} {'Agent AVEC':<15} {'Agent SANS':<15} {'DiffÃ©rence':<15}")
    print("-" * 80)
    
    metrics = [
        ('RÃ©compense moyenne', 'avg_reward', '.2f'),
        ('Ã‰tapes moyennes', 'avg_steps', '.1f'),
        ('Distance cible', 'avg_distance', '.3f'),
        ('Taux survie (%)', 'survival_rate', '.1f'),
        ('Collision obstacles (%)', 'collision_rate', '.1f'),
        ('Sortie limites (%)', 'bounds_rate', '.1f')
    ]
    
    for metric_name, key, fmt in metrics:
        val_with = stats_with[key]
        val_without = stats_without[key]
        diff = val_with - val_without
        
        # Formatage corrigÃ© - enlever les deux points du dÃ©but
        format_spec = fmt[1:] if fmt.startswith(':') else fmt
        val_with_str = f"{val_with:{format_spec}}"
        val_without_str = f"{val_without:{format_spec}}"
        diff_str = f"{diff:+{format_spec}}"
        
        print(f"{metric_name:<25} {val_with_str:<15} {val_without_str:<15} {diff_str:<15}")
    
    # Section spÃ©ciale pour les RÃ‰USSITES
    print(f"\nğŸ¯ FOCUS: TAUX DE RÃ‰USSITE (Survie 500 Ã©tapes)")
    print("-" * 50)
    success_with = stats_with['survival_count']
    success_without = stats_without['survival_count']
    success_diff = success_with - success_without
    
    print(f"Agent final_agent:              {success_with}/{num_episodes} rÃ©ussites ({stats_with['survival_rate']:.1f}%)")
    print(f"Agent final_agentWithoutObstacle: {success_without}/{num_episodes} rÃ©ussites ({stats_without['survival_rate']:.1f}%)")
    print(f"DiffÃ©rence:                     {success_diff:+d} rÃ©ussites")
    
    if success_diff > 0:
        print(f"âœ… L'agent final_agent rÃ©ussit {success_diff} fois de plus sur la map!")
        print(f"   â†’ EntraÃ®nÃ© avec obstacles = meilleure navigation")
    elif success_diff == 0:
        print(f"âš–ï¸  Les deux agents ont le mÃªme taux de rÃ©ussite")
    else:
        print(f"âš ï¸  L'agent final_agentWithoutObstacle rÃ©ussit {abs(success_diff)} fois de plus")
    
    # Section collisions obstacles
    print(f"\nğŸ’¥ FOCUS: COLLISIONS AVEC L'OBSTACLE")
    print("-" * 50)
    collision_with = stats_with['collision_count']
    collision_without = stats_without['collision_count']
    collision_reduction = collision_without - collision_with
    
    print(f"Agent final_agent:              {collision_with}/{num_episodes} collisions")
    print(f"Agent final_agentWithoutObstacle: {collision_without}/{num_episodes} collisions")
    
    if collision_reduction > 0:
        reduction_pct = (collision_reduction/collision_without*100) if collision_without > 0 else 0
        print(f"RÃ©duction:                      {collision_reduction:+d} collisions Ã©vitÃ©es (-{reduction_pct:.1f}%)")
        print(f"âœ… L'agent entraÃ®nÃ© avec obstacles Ã©vite mieux l'obstacle!")
    elif collision_reduction == 0:
        print(f"âš–ï¸  MÃªme nombre de collisions")
    else:
        print(f"âš ï¸  {abs(collision_reduction)} collisions de plus pour l'agent entraÃ®nÃ©")
    
    # Analyse des rÃ©sultats
    print(f"\nğŸ” ANALYSE COMPARATIVE:")
    print("=" * 60)
    
    survival_improvement = stats_with['survival_rate'] - stats_without['survival_rate']
    collision_improvement = stats_without['collision_rate'] - stats_with['collision_rate']
    
    # Analyse de la survie
    print(f"ğŸ“Š Taux de survie:")
    if survival_improvement > 20:
        print(f"   ï¿½ EXCELLENT: +{survival_improvement:.1f}% de rÃ©ussite")
        print(f"   â†’ L'agent entraÃ®nÃ© avec obstacles est BEAUCOUP plus performant!")
    elif survival_improvement > 10:
        print(f"   âœ… TRÃˆS BIEN: +{survival_improvement:.1f}% de rÃ©ussite")
        print(f"   â†’ L'entraÃ®nement avec obstacles a portÃ© ses fruits")
    elif survival_improvement > 0:
        print(f"   ğŸ‘ BIEN: +{survival_improvement:.1f}% de rÃ©ussite")
        print(f"   â†’ LÃ©gÃ¨re amÃ©lioration grÃ¢ce Ã  l'entraÃ®nement")
    elif survival_improvement == 0:
        print(f"   âš–ï¸  Ã‰GAL: MÃªme performance")
    else:
        print(f"   âš ï¸  SURPRENANT: {survival_improvement:.1f}% (agent sans obstacles meilleur)")
        print(f"   â†’ Possible que l'agent sans obstacles ait eu plus d'entraÃ®nement")
    
    # Analyse des collisions
    print(f"\nğŸ’¥ Ã‰vitement des collisions:")
    if collision_improvement > 20:
        print(f"   ğŸ›¡ï¸  EXCELLENT: {collision_improvement:.1f}% moins de collisions")
        print(f"   â†’ L'agent a bien appris Ã  Ã©viter les obstacles!")
    elif collision_improvement > 10:
        print(f"   ğŸ‘ BIEN: {collision_improvement:.1f}% moins de collisions")
        print(f"   â†’ AmÃ©lioration notable de la navigation")
    elif collision_improvement > 0:
        print(f"   â†—ï¸  LÃ‰GÃˆRE AMÃ‰LIORATION: {collision_improvement:.1f}% moins de collisions")
    elif collision_improvement == 0:
        print(f"   âš–ï¸  Ã‰GAL: MÃªme nombre de collisions")
    else:
        print(f"   âš ï¸  {abs(collision_improvement):.1f}% plus de collisions")
        print(f"   â†’ L'entraÃ®nement n'a pas amÃ©liorÃ© l'Ã©vitement")
    
    # Recommandations
    print(f"\nğŸ’¡ RECOMMANDATIONS:")
    if collision_improvement < 10:
        print("ğŸ”„ L'agent avec obstacles peut encore s'amÃ©liorer:")
        print("   â€¢ Plus d'entraÃ®nement (augmenter timesteps)")
        print("   â€¢ Penalty collision plus Ã©levÃ©e (-15 au lieu de -10)")
        print("   â€¢ RÃ©compense pour Ã©vitement d'obstacles")
    
    if stats_with['survival_rate'] < 20:
        print("ï¿½ Curriculum learning recommandÃ©:")
        print("   â€¢ Commencer avec 1 obstacle, puis 2, puis 3")
        print("   â€¢ Obstacles plus grands au dÃ©but")
    
    # Verdict final - QUI GAGNE?
    print(f"\nğŸ† VERDICT FINAL:")
    print("=" * 60)
    
    if success_with > success_without:
        winner = "final_agent (entraÃ®nÃ© AVEC obstacles)"
        margin = success_with - success_without
        print(f"ğŸ¥‡ GAGNANT: {winner}")
        print(f"   âœ… {success_with} rÃ©ussites VS {success_without} rÃ©ussites")
        print(f"   â†’ Marge de victoire: +{margin} rÃ©ussites sur {num_episodes} essais")
        print(f"   ï¿½ L'entraÃ®nement avec obstacles a Ã©tÃ© efficace!")
    elif success_without > success_with:
        winner = "final_agentWithoutObstacle (entraÃ®nÃ© SANS obstacles)"
        margin = success_without - success_with
        print(f"ğŸ¥‡ GAGNANT: {winner}")
        print(f"   âœ… {success_without} rÃ©ussites VS {success_with} rÃ©ussites")
        print(f"   â†’ Marge de victoire: +{margin} rÃ©ussites sur {num_episodes} essais")
        print(f"   âš ï¸  RÃ©sultat surprenant!")
    else:
        print(f"ğŸ¤ Ã‰GALITÃ‰ PARFAITE")
        print(f"   â†’ Les deux agents ont {success_with} rÃ©ussites chacun")
        print(f"   â†’ Performance identique sur {num_episodes} essais")
    
    env.close()
    return stats_with, stats_without

def list_available_models():
    """Liste les modÃ¨les disponibles dans le rÃ©pertoire"""
    import glob
    
    print("ğŸ“‚ MODÃˆLES DISPONIBLES:")
    print("-" * 40)
    
    # Chercher tous les fichiers .zip
    model_files = glob.glob("*.zip")
    checkpoint_files = glob.glob("checkpoint_*.zip")
    
    if model_files:
        for model in sorted(model_files):
            print(f"   âœ… {model}")
    else:
        print("   âŒ Aucun modÃ¨le trouvÃ© dans le rÃ©pertoire courant")
        print("   ğŸ’¡ Assurez-vous d'Ãªtre dans le dossier examples/")
        print("   ğŸ’¡ L'entraÃ®nement doit Ãªtre terminÃ© pour crÃ©er les fichiers .zip")
    
    return model_files

if __name__ == "__main__":
    print("ğŸ¤– COMPARAISON AGENTS: AVEC vs SANS obstacles")
    print("=" * 60)
    
    # D'abord, lister les modÃ¨les disponibles
    available_models = list_available_models()
    
    if not available_models:
        print("\nâš ï¸  Aucun modÃ¨le disponible pour l'analyse")
        print("\nğŸ“š Ã‰TAPES NÃ‰CESSAIRES:")
        print("   1. Terminer l'entraÃ®nement avec obstacles")
        print("   2. S'assurer d'avoir 'final_agentWithoutObstacle.zip'")
        print("   3. Relancer ce script")
        exit(1)
    
    # Chemins des modÃ¨les
    agent_with_obstacles = "final_agent"  # Agent entraÃ®nÃ© avec obstacles
    agent_without_obstacles = "final_agentWithoutObstacle"  # Agent entraÃ®nÃ© sans obstacles
    
    # 1. Comparaison quantitative sur 30 essais
    print("\nğŸ”¬ ANALYSE COMPARATIVE - 30 ESSAIS CHACUN:")
    result = compare_agents_with_obstacles(
        agent_with_obstacles, 
        agent_without_obstacles, 
        num_episodes=30
    )
    
    if result is None:
        print("\nâš ï¸  Analyse interrompue - modÃ¨les non disponibles")
        exit(1)
    
    stats_with, stats_without = result
    
    print("\n" + "=" * 70)
    print("ğŸ‰ ANALYSE TERMINÃ‰E!")
    print("=" * 70)
    print(f"âœ… 30 essais par agent sur la map fixe avec obstacle")
    print(f"ğŸ—ºï¸  Configuration: Drone (150,400) â†’ Cible (650,400) + obstacle central")
    print("=" * 70)